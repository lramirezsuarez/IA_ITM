{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th><img align=\"center\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/UNAL_Aplicación_Medell%C3%ADn.svg/1280px-UNAL_Aplicación_Medell%C3%ADn.svg.png\" width=\"300\"/></th>\n",
    "    <th><img align=\"center\" src=\"http://www.redttu.edu.co/es/wp-content/uploads/2016/01/itm.png\" width=\"300\"/> </th> \n",
    "    <th><img align=\"center\" src=\"https://www.cienciasdelaadministracion.uns.edu.ar/wp-content/themes/enlighten-pro/images/logo-uns-horizontal.png\" width=\"300\"/></th>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(data_type, noise=0.2):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    if data_type == 'moons':\n",
    "        X, Y = datasets.make_moons(200, noise=noise)\n",
    "    elif data_type == 'circles':\n",
    "        X, Y = sklearn.datasets.make_circles(200, noise=noise)\n",
    "    elif data_type == 'blobs':\n",
    "        X, Y = sklearn.datasets.make_blobs(centers=2, cluster_std=noise)\n",
    "    return X, Y\n",
    "\n",
    "def visualize_lr(W1, b1, W2, b2, W3, b3, X, Y):\n",
    "    X = X.T\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = predict_multilayer(W1,b1,W2,b2,W3,b3,np.c_[xx.ravel(), yy.ravel()].T)\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.bone)\n",
    "    \n",
    "    color = ['blue' if y == 1 else 'red' for y in np.squeeze(Y)]\n",
    "    plt.scatter(X[:,0], X[:,1], color=color)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Pedro Atencio Ortiz - 2019 (pedroatencio@itm.edu.co)\n",
    "\n",
    "\n",
    "# 2. Operador XOR y Regresores en Cadena\n",
    "\n",
    "En este notebook abordaremos los siguientes tópicos:\n",
    "\n",
    "- Clasificación no-lineal.\n",
    "- XOR y su descomposición lineal.\n",
    "- Regresores lineales en capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2.1. Clasificación no - lineal\n",
    "\n",
    "Se define un problema de clasificación lineal como un problema para el cuál  __no existe__ un hiperplano en $\\rm I\\!R^{nx-1}$ que permita separar las categorías de los objetos con un grado de precisión (accuracy) $> \\tau$. En el gráfico siguiente se puede observar uno de estos problemas de clasificación no-lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_data('circles', 0.1)\n",
    "Y = Y.reshape(1,len(Y))\n",
    "\n",
    "color = ['blue' if y == 1 else 'red' for y in np.squeeze(Y)] # una lista para darle color a las clases\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X[:,0], X[:,1], color=color)\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2.2. XOR y su descomposión lineal\n",
    "\n",
    "El operador XOR puede utilizarse para ilustrar un problema de clasificación lineal que se puede descomponer en operaciones lineales o clasificaciones lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "color= ['blue' if y == 1 else 'red' for y in np.squeeze(Y)]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0], X[:,1], color=color)\n",
    "plt.grid()\n",
    "plt.xlabel(r'$p$', fontsize=12)\n",
    "plt.ylabel(r'$q$', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Revisemos el operador y trabajemos sobre sus tablas de verdad:\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><font size=5>$p \\oplus q = (p \\wedge \\neg q) \\vee (\\neg p \\wedge q) $</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y1 = np.array([[0, 1, 1, 1]])\n",
    "\n",
    "X2 = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y2 = np.array([[1, 1, 1, 0]])\n",
    "\n",
    "X3 = np.array([[0,1],[1,1],[1,1],[1,0]])\n",
    "Y3 = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "color1 = ['blue' if y == 1 else 'red' for y in np.squeeze(Y1)]\n",
    "color2 = ['blue' if y == 1 else 'red' for y in np.squeeze(Y2)]\n",
    "color3 = ['blue' if y == 1 else 'red' for y in np.squeeze(Y3)]\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title(r'L = $(p \\wedge \\neg q)$')\n",
    "plt.scatter(X1[:,0], X1[:,1], color=color1)\n",
    "plt.grid()\n",
    "plt.xlabel(r'$p$', fontsize=12)\n",
    "plt.ylabel(r'$q$', fontsize=12)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title(r'$R = (\\neg p \\wedge q)$')\n",
    "plt.scatter(X2[:,0], X2[:,1], color=color2)\n",
    "plt.grid()\n",
    "plt.xlabel(r'$p$', fontsize=12)\n",
    "plt.ylabel(r'$q$', fontsize=12)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title(r'$L \\vee R$')\n",
    "plt.scatter(X3[:,0], X3[:,1], color=color3)\n",
    "plt.grid()\n",
    "plt.xlabel(r'$L$', fontsize=12)\n",
    "plt.ylabel(r'$R$', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "El análisis anterior permite suponer que es posible entonces utilizar tres regresores logísticos para aprender cada una de las tres operaciones anteriores y concatenarlos de tal forma que permitan predecir el operador XOR a partir de las entradas.\n",
    "\n",
    "Para ello, entrenaremos cada regresor por separado utilizando las tablas de verdad construidas en cada caso y finalmente los concatenaremos en una sola estructura como se puede observar en la siguiente figura:\n",
    "\n",
    "<img align=\"center\" src=\"https://github.com/psatencio/intro_keras/blob/master/figures/layered_regresor.png?raw=true\" width=\"500\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "Analicemos el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilicemos las mismas operaciones vectorizadas para los regresores logisticos.\n",
    "\n",
    "def linear_activation(W, b, X):\n",
    "    z = np.dot(W.T,X) + b\n",
    "    \n",
    "    return z\n",
    "\n",
    "def sigmoid(z):\n",
    "    a = 1. / (1. + np.exp(-z)) \n",
    "    \n",
    "    return a \n",
    "\n",
    "def logloss(y, a):\n",
    "    return -(y * np.log(a) + (1-y) * np.log(1-a))\n",
    "\n",
    "def cost(L):\n",
    "    return np.mean(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets, 1 por regresor\n",
    "\n",
    "X1 = np.array([[0,0],[0,1],[1,0],[1,1]]).T\n",
    "Y1 = np.array([[0, 1, 1, 1]])\n",
    "\n",
    "X2 = np.array([[0,0],[0,1],[1,0],[1,1]]).T\n",
    "Y2 = np.array([[1, 1, 1, 0]])\n",
    "\n",
    "X3 = np.array([[0,1],[1,1],[1,1],[1,0]]).T\n",
    "Y3 = np.array([[0, 1, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros de los regresores 1, 2 y 3\n",
    "np.random.seed(2)\n",
    "\n",
    "m = len(X1)\n",
    "nx = X1.shape[0]\n",
    "\n",
    "W1 = np.random.random([nx, 1]) \n",
    "b1 = np.random.random()\n",
    "\n",
    "W2 = np.random.random([nx, 1]) \n",
    "b2 = np.random.random()\n",
    "\n",
    "W3 = np.random.random([nx, 1])\n",
    "b3 = np.random.random()\n",
    "\n",
    "# Parametros del descenso del gradiente\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Computacion de las activaciones de cada regresor\n",
    "    Z1 = linear_activation(W1,b1,X1)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    Z2 = linear_activation(W2,b2,X2)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    Z3 = linear_activation(W3,b3,X3)\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    # Calculo de gradientes\n",
    "    dZ1 = A1 - Y1\n",
    "    dW1 = np.dot(X1, dZ1.T) / m\n",
    "    db1 = np.sum(dZ1) / m\n",
    "    \n",
    "    dZ2 = A2 - Y2\n",
    "    dW2 = np.dot(X2, dZ2.T) / m\n",
    "    db2 = np.sum(dZ2) / m\n",
    "    \n",
    "    dZ3 = A3 - Y3\n",
    "    dW3 = np.dot(X3, dZ3.T) / m\n",
    "    db3 = np.sum(dZ3) / m\n",
    "    \n",
    "    # Actualizacion de parametros\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W3 -= learning_rate * dW3\n",
    "    b3 -= learning_rate * db3\n",
    "    \n",
    "    # Estimacion del costo\n",
    "    J1 = cost(logloss(Y1,A1))\n",
    "    J2 = cost(logloss(Y2,A2))\n",
    "    J3 = cost(logloss(Y3,A3))\n",
    "\n",
    "print(\"W1 actualizado: \",W1, \"b1 actualizado: \", b1, \" Costo final: \", J1)\n",
    "print(\"W2 actualizado: \",W2, \"b2 actualizado: \", b2, \" Costo final: \", J2)\n",
    "print(\"W3 actualizado: \",W3, \"b3 actualizado: \", b3, \" Costo final: \", J3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Si bien ahora tenemos nuestros regresor entrenados de manera independiente, debemos conectarlos para poder predecir el valor de salida desde la entrada a los regresores 1 y 2, posteriormente concatenar ambas salidas como entradas para el regresor 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multilayer(W1,b1,W2,b2,W3,b3,X):\n",
    "    Z1 = linear_activation(W1,b1,X)\n",
    "    A1 = sigmoid(Z1) #salida del regresor 1\n",
    "    \n",
    "    Z2 = linear_activation(W2,b2,X)\n",
    "    A2 = sigmoid(Z2) #salida del regresor 2\n",
    "    \n",
    "    X3 = np.concatenate((A1,A2), axis=0) #En este punto concatenamos A1 y A2 como entradas para el regresor 3\n",
    "    Z3 = linear_activation(W3, b3, X3)\n",
    "    A3 = sigmoid(Z3) #salida del regresor 3\n",
    "    \n",
    "    return A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_lr(W1, b1, W2, b2, W3, b3, X, Y) #Grafiquemos el mapa de separacion de nuestros regresores en cadena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<font size=4>\n",
    "    \n",
    "__Analicemos__: \n",
    "\n",
    "Si bien este ejercicio muestra que un conjunto de regresores en cadena puede aproximar problemas no-lineales, finalmente, esta aproximación de entrenamiento es inviable en cualquier caso. En qué radica dicha inviabilidad?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
